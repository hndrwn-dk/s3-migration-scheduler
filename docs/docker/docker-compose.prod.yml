version: '3.8'

services:
  backend:
    build:
      context: .
      dockerfile: Dockerfile.backend
      target: production
    container_name: s3-migration-backend-prod
    ports:
      - "5000:5000"
    volumes:
      - sqlite_data:/app/data
      - logs_data:/app/logs
      - ./config:/app/config:ro
    environment:
      - NODE_ENV=production
      - FRONTEND_URL=http://localhost
      - DB_PATH=/app/data/migrations.db
      - LOG_LEVEL=info
      - MAX_CONCURRENT_MIGRATIONS=5
    networks:
      - s3-migration-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:5000/api/health', (r) => process.exit(r.statusCode === 200 ? 0 : 1))"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'

  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
      target: production
    container_name: s3-migration-frontend-prod
    ports:
      - "80:80"
    environment:
      - REACT_APP_API_URL=/api
      - REACT_APP_WS_URL=/ws
    networks:
      - s3-migration-network
    depends_on:
      backend:
        condition: service_healthy
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 128M
          cpus: '0.25'

  # Optional: Add a reverse proxy for SSL termination in production
  # nginx-proxy:
  #   image: nginx:alpine
  #   container_name: s3-migration-proxy
  #   ports:
  #     - "443:443"
  #   volumes:
  #     - ./nginx/ssl:/etc/nginx/ssl:ro
  #     - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
  #   networks:
  #     - s3-migration-network
  #   depends_on:
  #     - frontend
  #   restart: unless-stopped

networks:
  s3-migration-network:
    driver: bridge

volumes:
  sqlite_data:
    driver: local
  logs_data:
    driver: local